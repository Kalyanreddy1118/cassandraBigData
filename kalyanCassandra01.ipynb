{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10921eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe2bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassandraConnection:\n",
    "    def __init__(self, secure_connect_bundle, token_file):\n",
    "        self.secure_connect_bundle = secure_connect_bundle\n",
    "        self.token_file = token_file\n",
    "        self.session = None\n",
    "        self.cluster = None\n",
    "        self._connect_to_cassandra()\n",
    "\n",
    "    def _connect_to_cassandra(self):\n",
    "        \"\"\"Connects to Cassandra using the provided secure bundle and credentials.\"\"\"\n",
    "        with open(self.token_file) as f:\n",
    "            secrets = json.load(f)\n",
    "\n",
    "        CLIENT_ID = secrets[\"clientId\"]\n",
    "        CLIENT_SECRET = secrets[\"secret\"]\n",
    "\n",
    "        auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
    "        self.cluster = Cluster(cloud={'secure_connect_bundle': self.secure_connect_bundle}, auth_provider=auth_provider)\n",
    "        self.session = self.cluster.connect()\n",
    "\n",
    "    def get_session(self):\n",
    "        \"\"\"Return the Cassandra session.\"\"\"\n",
    "        return self.session\n",
    "\n",
    "    def get_cluster(self):\n",
    "        \"\"\"Return the Cassandra cluster.\"\"\"\n",
    "        return self.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a240351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, session, keyspace, table):\n",
    "        self.session = session\n",
    "        self.keyspace = keyspace\n",
    "        self.table = table\n",
    "\n",
    "    def load_raw_data(self, df):\n",
    "        \"\"\"Loading raw data into Cassandra Bronze table.\"\"\"\n",
    "        self._create_table_if_not_exists()\n",
    "        insert_query = self._prepare_insert_query()\n",
    "        for _, row in df.iterrows():\n",
    "            self.session.execute(insert_query, (\n",
    "                row['Region'], row['Country'], row['Item Type'], row['Sales Channel'],\n",
    "                row['Order Priority'], row['Order Date'], row['Order ID'], row['Ship Date'],\n",
    "                row['UnitsSold'], row['UnitPrice'], row['UnitCost'],\n",
    "                row['TotalRevenue'], row['TotalCost'], row['TotalProfit']\n",
    "            ))\n",
    "\n",
    "    def _create_table_if_not_exists(self):\n",
    "        \"\"\"Create table if it doesn't exist.\"\"\"\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {self.keyspace}.{self.table} (\n",
    "            region TEXT,\n",
    "            country TEXT,\n",
    "            itemtype TEXT,\n",
    "            saleschannel TEXT,\n",
    "            orderPriority TEXT,\n",
    "            orderDate TEXT,\n",
    "            orderId BIGINT PRIMARY KEY,\n",
    "            shipDate TEXT,\n",
    "            unitsSold INT,\n",
    "            unitPrice FLOAT,\n",
    "            unitCost FLOAT,\n",
    "            totalRevenue FLOAT,\n",
    "            totalCost FLOAT,\n",
    "            totalProfit FLOAT\n",
    "        )\n",
    "        \"\"\"\n",
    "        self.session.execute(create_table_query)\n",
    "\n",
    "    def _prepare_insert_query(self):\n",
    "        \"\"\"Prepare the insert query.\"\"\"\n",
    "        return self.session.prepare(f\"\"\"\n",
    "        INSERT INTO {self.keyspace}.{self.table} (\n",
    "            region, country, itemtype, saleschannel, orderPriority,\n",
    "            orderDate, orderId, shipDate, unitsSold, unitPrice,\n",
    "            unitCost, totalRevenue, totalCost, totalProfit\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9b3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    @staticmethod\n",
    "    def bronze_to_silver(dataframe):\n",
    "        \"\"\"\n",
    "        Cleans and processes the bronze-level DataFrame to silver-level.\n",
    "        \"\"\"\n",
    "        # Handle missing values: Drop rows where critical fields are null\n",
    "        critical_columns = [\n",
    "            \"region\", \"country\", \"itemtype\", \"saleschannel\", \n",
    "            \"orderpriority\", \"orderdate\", \"orderid\", \"shipdate\"\n",
    "        ]\n",
    "        dataframe = dataframe.dropna(subset=critical_columns)\n",
    "        \n",
    "        # Ensuring correct data types\n",
    "        dataframe[\"orderid\"] = dataframe[\"orderid\"].astype(int)\n",
    "        dataframe[\"unitssold\"] = dataframe[\"unitssold\"].astype(int)\n",
    "        dataframe[\"unitprice\"] = dataframe[\"unitprice\"].astype(float)\n",
    "        dataframe[\"unitcost\"] = dataframe[\"unitcost\"].astype(float)\n",
    "        dataframe[\"totalrevenue\"] = dataframe[\"totalrevenue\"].astype(float)\n",
    "        dataframe[\"totalcost\"] = dataframe[\"totalcost\"].astype(float)\n",
    "        dataframe[\"totalprofit\"] = dataframe[\"totalprofit\"].astype(float)\n",
    "        \n",
    "        # Converting dates to uniform format\n",
    "        date_format = \"%m/%d/%Y\"\n",
    "        dataframe[\"orderdate\"] = pd.to_datetime(dataframe[\"orderdate\"], format=date_format, errors=\"coerce\")\n",
    "        dataframe[\"shipdate\"] = pd.to_datetime(dataframe[\"shipdate\"], format=date_format, errors=\"coerce\")\n",
    "        \n",
    "        # Removing rows with invalid dates\n",
    "        dataframe = dataframe.dropna(subset=[\"orderdate\", \"shipdate\"])\n",
    "        \n",
    "        # Standardizing categorical fields to lowercase\n",
    "        dataframe[\"region\"] = dataframe[\"region\"].str.lower()\n",
    "        dataframe[\"country\"] = dataframe[\"country\"].str.lower()\n",
    "        dataframe[\"itemtype\"] = dataframe[\"itemtype\"].str.lower()\n",
    "        dataframe[\"saleschannel\"] = dataframe[\"saleschannel\"].str.lower()\n",
    "        dataframe[\"orderpriority\"] = dataframe[\"orderpriority\"].str.lower()\n",
    "        \n",
    "        # Removing invalid records: Check if orderDate <= shipDate\n",
    "        dataframe = dataframe[dataframe[\"orderdate\"] <= dataframe[\"shipdate\"]]\n",
    "        \n",
    "        # Add a \"processed_at\" column to track processing time\n",
    "        dataframe[\"processed_at\"] = datetime.now()\n",
    "        \n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c99da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SilverDataLoader:\n",
    "    def __init__(self, session, keyspace, silvertable):\n",
    "        self.session = session\n",
    "        self.keyspace = keyspace\n",
    "        self.silvertable = silvertable\n",
    "\n",
    "    def load_data(self, silver_df):\n",
    "        \"\"\"Load cleaned silver data into Cassandra.\"\"\"\n",
    "        self._create_table_if_not_exists()\n",
    "        self._insert_data(silver_df)\n",
    "\n",
    "    def _create_table_if_not_exists(self):\n",
    "        \"\"\"Create the Silver table if it doesn't exist.\"\"\"\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {self.keyspace}.{self.silvertable} (\n",
    "            orderid BIGINT PRIMARY KEY,\n",
    "            country TEXT,\n",
    "            itemtype TEXT,\n",
    "            orderdate DATE,\n",
    "            orderpriority TEXT,\n",
    "            region TEXT,\n",
    "            saleschannel TEXT,\n",
    "            shipdate DATE,\n",
    "            totalcost FLOAT,\n",
    "            totalprofit FLOAT,\n",
    "            totalrevenue FLOAT,\n",
    "            unitcost FLOAT,\n",
    "            unitprice FLOAT,\n",
    "            unitssold INT,\n",
    "            processed_at TIMESTAMP\n",
    "        );\n",
    "        \"\"\"\n",
    "        self.session.execute(create_table_query)\n",
    "\n",
    "    def _insert_data(self, silver_df):\n",
    "        \"\"\"Insert data into the Silver table.\"\"\"\n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO {self.keyspace}.{self.silvertable} (\n",
    "            orderid, country, itemtype, orderdate, orderpriority, region, \n",
    "            saleschannel, shipdate, totalcost, totalprofit, totalrevenue, \n",
    "            unitcost, unitprice, unitssold, processed_at\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        prepared = self.session.prepare(insert_query)\n",
    "        \n",
    "        for _, row in silver_df.iterrows():\n",
    "            self.session.execute(prepared, (\n",
    "                int(row[\"orderid\"]),\n",
    "                row[\"country\"],\n",
    "                row[\"itemtype\"],\n",
    "                row[\"orderdate\"].date(),  \n",
    "                row[\"orderpriority\"],\n",
    "                row[\"region\"],\n",
    "                row[\"saleschannel\"],\n",
    "                row[\"shipdate\"].date(),\n",
    "                float(row[\"totalcost\"]),\n",
    "                float(row[\"totalprofit\"]),\n",
    "                float(row[\"totalrevenue\"]),\n",
    "                float(row[\"unitcost\"]),\n",
    "                float(row[\"unitprice\"]),\n",
    "                int(row[\"unitssold\"]),\n",
    "                row[\"processed_at\"].to_pydatetime() \n",
    "            ))\n",
    "\n",
    "        print(\"Silver Data loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5f0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalRevenueByRegion:\n",
    "    def __init__(self, session, keyspace, gold_table):\n",
    "        self.session = session\n",
    "        self.keyspace = keyspace\n",
    "        self.gold_table = gold_table\n",
    "\n",
    "    def aggregate(self, silver_df):\n",
    "        \"\"\"Aggregate total revenue by region.\"\"\"\n",
    "        aggregated_df = silver_df.groupby('region', as_index=False)['totalrevenue'].sum()\n",
    "        self._load_to_cassandra(aggregated_df)\n",
    "\n",
    "    def _load_to_cassandra(self, aggregated_df):\n",
    "        \"\"\"Load aggregated data into Cassandra gold table.\"\"\"\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {self.keyspace}.{self.gold_table} (\n",
    "            region TEXT PRIMARY KEY,\n",
    "            totalrevenue FLOAT\n",
    "        );\n",
    "        \"\"\"\n",
    "        self.session.execute(create_table_query)\n",
    "        \n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO {self.keyspace}.{self.gold_table} (region, totalrevenue) \n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "        prepared = self.session.prepare(insert_query)\n",
    "\n",
    "        for _, row in aggregated_df.iterrows():\n",
    "            self.session.execute(prepared, (row[\"region\"], row[\"totalrevenue\"]))\n",
    "        \n",
    "        print(\"Total Revenue by Region loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d6aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalProfitByRegion:\n",
    "    def __init__(self, session, keyspace, gold_table):\n",
    "        self.session = session\n",
    "        self.keyspace = keyspace\n",
    "        self.gold_table = gold_table\n",
    "\n",
    "    def aggregate(self, silver_df):\n",
    "        \"\"\"Aggregate total profit by region.\"\"\"\n",
    "        aggregated_df = silver_df.groupby('region', as_index=False)['totalprofit'].sum()\n",
    "        self._load_to_cassandra(aggregated_df)\n",
    "\n",
    "    def _load_to_cassandra(self, aggregated_df):\n",
    "        \"\"\"Load aggregated data into Cassandra gold table.\"\"\"\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {self.keyspace}.{self.gold_table} (\n",
    "            region TEXT PRIMARY KEY,\n",
    "            totalprofit FLOAT\n",
    "        );\n",
    "        \"\"\"\n",
    "        self.session.execute(create_table_query)\n",
    "        \n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO {self.keyspace}.{self.gold_table} (region, totalprofit) \n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "        prepared = self.session.prepare(insert_query)\n",
    "\n",
    "        for _, row in aggregated_df.iterrows():\n",
    "            self.session.execute(prepared, (row[\"region\"], row[\"totalprofit\"]))\n",
    "        \n",
    "        print(\"Total Profit by Region loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732c542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalUnitsSoldByRegion:\n",
    "    def __init__(self, session, keyspace, gold_table):\n",
    "        self.session = session\n",
    "        self.keyspace = keyspace\n",
    "        self.gold_table = gold_table\n",
    "\n",
    "    def aggregate(self, silver_df):\n",
    "        \"\"\"Aggregate total units sold by region.\"\"\"\n",
    "        aggregated_df = silver_df.groupby('region', as_index=False)['unitssold'].sum()\n",
    "        self._load_to_cassandra(aggregated_df)\n",
    "\n",
    "    def _load_to_cassandra(self, aggregated_df):\n",
    "        \"\"\"Load aggregated data into Cassandra gold table.\"\"\"\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {self.keyspace}.{self.gold_table} (\n",
    "            region TEXT PRIMARY KEY,\n",
    "            unitssold INT\n",
    "        );\n",
    "        \"\"\"\n",
    "        self.session.execute(create_table_query)\n",
    "        \n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO {self.keyspace}.{self.gold_table} (region, unitssold) \n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "        prepared = self.session.prepare(insert_query)\n",
    "\n",
    "        for _, row in aggregated_df.iterrows():\n",
    "            self.session.execute(prepared, (row[\"region\"], row[\"unitssold\"]))\n",
    "        \n",
    "        print(\"Total Units Sold by Region loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3464d4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Extracted Successfully!\n",
      "Silver Data loaded successfully!\n",
      "Total Revenue by Region loaded successfully!\n",
      "Total Profit by Region loaded successfully!\n",
      "Total Units Sold by Region loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    secure_connect_bundle = 'secure-connect-kalyanc.zip'\n",
    "    token_file = \"kalyanc-token.json\"\n",
    "    keyspace = 'cdb'\n",
    "    bronze_table = 'bronze_sales'\n",
    "    silver_table = 'silver_sales'\n",
    "\n",
    "    cassandra_connection = CassandraConnection(secure_connect_bundle, token_file)\n",
    "    session = cassandra_connection.get_session()\n",
    "\n",
    "    # Load raw data to Cassandra bronze table\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/gchandra10/filestorage/main/sales_100.csv\")\n",
    "    data_loader = DataLoader(session, keyspace, bronze_table)\n",
    "    data_loader.load_raw_data(df)\n",
    "\n",
    "    # Extract data from the Bronze table\n",
    "    query = f\"SELECT * FROM {keyspace}.{bronze_table}\"\n",
    "    rows = session.execute(query)\n",
    "    data = [row._asdict() for row in rows]\n",
    "    df1 = pd.DataFrame(data)\n",
    "    print('Data Extracted Successfully!')\n",
    "\n",
    "    # Clean and process the data for Silver stage\n",
    "    silver_df = DataCleaner.bronze_to_silver(df1)\n",
    "\n",
    "    # Load the cleaned data into the Silver table\n",
    "    silver_data_loader = SilverDataLoader(session, keyspace, silver_table)\n",
    "    silver_data_loader.load_data(silver_df)\n",
    "    \n",
    "    # Create Gold Tables (Aggregation)\n",
    "    total_revenue = TotalRevenueByRegion(session, keyspace, \"total_revenue_by_region\")\n",
    "    total_profit = TotalProfitByRegion(session, keyspace, \"total_profit_by_region\")\n",
    "    total_units_sold = TotalUnitsSoldByRegion(session, keyspace, \"total_units_sold_by_region\")\n",
    "\n",
    "    # Perform aggregations\n",
    "    total_revenue.aggregate(silver_df)\n",
    "    total_profit.aggregate(silver_df)\n",
    "    total_units_sold.aggregate(silver_df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9a60f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
